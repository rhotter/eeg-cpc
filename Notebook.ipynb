{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import mne\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eegcpc.helper import fetch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.time_frequency import psd_welch\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subjects = [i for i in range(0,20)]\n",
    "test_subjects = [i for i in range(20,30)]\n",
    "recordings = [1] # 2 recordings per subject\n",
    "\n",
    "MAPPING = {'EOG horizontal': 'eog',\n",
    "           'Resp oro-nasal': 'misc',\n",
    "           'EMG submental': 'misc',\n",
    "           'Temp rectal': 'misc',\n",
    "           'Event marker': 'misc'}\n",
    "\n",
    "annotation_desc_2_event_id = {'Sleep stage W': 1,\n",
    "                              'Sleep stage 1': 2,\n",
    "                              'Sleep stage 2': 3,\n",
    "                              'Sleep stage 3': 4,\n",
    "                              'Sleep stage 4': 4,\n",
    "                              'Sleep stage R': 5}\n",
    "event_id = {'Sleep stage W': 1,\n",
    "            'Sleep stage 1': 2,\n",
    "            'Sleep stage 2': 3,\n",
    "            'Sleep stage 3/4': 4,\n",
    "            'Sleep stage R': 5} # unifies stages 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(subjects, recordings, filter=False):\n",
    "    files = fetch_data(subjects=subjects, recording=recordings)\n",
    "    epochs = []\n",
    "    for x in files:\n",
    "        print(\"Loading\", x[0])\n",
    "        # load the data\n",
    "        edf_file = x[0]\n",
    "        annot_file = x[1]\n",
    "        raw = mne.io.read_raw_edf(edf_file, verbose='ERROR')\n",
    "        annot_train = mne.read_annotations(annot_file)\n",
    "\n",
    "        raw.set_annotations(annot_train, emit_warning=False)\n",
    "        raw.set_channel_types(MAPPING)\n",
    "        \n",
    "        if filter:\n",
    "            raw.load_data()\n",
    "            raw.filter(None, 30., fir_design='firwin') # low pass filter\n",
    "\n",
    "        # extract epochs\n",
    "        events_train, _ = mne.events_from_annotations(\n",
    "            raw, event_id=annotation_desc_2_event_id, chunk_duration=30., verbose='ERROR')\n",
    "\n",
    "        tmax = 30. - 1. / raw.info['sfreq']  # tmax in included\n",
    "        recording_epochs = mne.Epochs(raw=raw, events=events_train,\n",
    "                              event_id=event_id, tmin=0., tmax=tmax, baseline=None, verbose='ERROR')\n",
    "        epochs.append(recording_epochs)\n",
    "    epochs = mne.concatenate_epochs(epochs)\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand Engineered Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/raphael_hotter/datasets/SC4001E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4011E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4021E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4031E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4041E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4051E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4061E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4071E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4081E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4091E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4101E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4111E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4121E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4131E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4141E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4151E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4161E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4171E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4181E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4191E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4201E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4211E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4221E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4231E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4241E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4251E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4261F0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4271F0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4281G0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4291G0-PSG.edf\n"
     ]
    }
   ],
   "source": [
    "epochs_train = load_data(train_subjects, recordings, filter=False)\n",
    "epochs_test = load_data(test_subjects, recordings, filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eeg_power_band(epochs):\n",
    "    \"\"\"EEG relative power band feature extraction.\n",
    "\n",
    "    This function takes an ``mne.Epochs`` object and creates EEG features based\n",
    "    on relative power in specific frequency bands that are compatible with\n",
    "    scikit-learn.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    epochs : Epochs\n",
    "        The data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : numpy array of shape [n_samples, 5]\n",
    "        Transformed data.\n",
    "    \"\"\"\n",
    "    # specific frequency bands\n",
    "    FREQ_BANDS = {\"delta\": [0.5, 4.5],\n",
    "                  \"theta\": [4.5, 8.5],\n",
    "                  \"alpha\": [8.5, 11.5],\n",
    "                  \"sigma\": [11.5, 15.5],\n",
    "                  \"beta\": [15.5, 30]}\n",
    "\n",
    "    psds, freqs = psd_welch(epochs, picks='eeg', fmin=0.5, fmax=30.)\n",
    "    # Normalize the PSDs\n",
    "    psds /= np.sum(psds, axis=-1, keepdims=True)\n",
    "\n",
    "    X = []\n",
    "    for fmin, fmax in FREQ_BANDS.values():\n",
    "        psds_band = psds[:, :, (freqs >= fmin) & (freqs < fmax)].mean(axis=-1)\n",
    "        X.append(psds_band.reshape(len(psds), -1))\n",
    "\n",
    "    return np.concatenate(X, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hand_engineered_baseline(epochs_train, epochs_test):\n",
    "    pipe = make_pipeline(FunctionTransformer(eeg_power_band, validate=False),\n",
    "                     RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    # Train\n",
    "    y_train = epochs_train.events[:, 2]\n",
    "    pipe.fit(epochs_train, y_train)\n",
    "\n",
    "    # Test\n",
    "    y_pred = pipe.predict(epochs_test)\n",
    "\n",
    "    # Assess the results\n",
    "    y_test = epochs_test.events[:, 2]\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Accuracy score: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Accuracy score: 0.8587653416376626\n"
     ]
    }
   ],
   "source": [
    "hand_engineered_baseline(epochs_train, epochs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Deep Learning Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/raphael_hotter/datasets/SC4001E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4011E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4021E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4031E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4041E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4051E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4061E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4071E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4081E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4091E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4201E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4211E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4221E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4231E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4241E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4251E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4261F0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4271F0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4281G0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4291G0-PSG.edf\n"
     ]
    }
   ],
   "source": [
    "epochs_train = load_data(train_subjects, recordings, filter=True)\n",
    "epochs_test = load_data(test_subjects, recordings, filter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Epochs  |   27295 events (all good), 0 - 29.99 sec, baseline off, ~1.22 GB, data loaded,\n",
       " 'Sleep stage 1': 1266\n",
       " 'Sleep stage 2': 4861\n",
       " 'Sleep stage 3/4': 713\n",
       " 'Sleep stage R': 1796\n",
       " 'Sleep stage W': 18659>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_train.pick_types(eeg=True, verbose='ERROR') # only keep EEG channels\n",
    "epochs_test.pick_types(eeg=True, verbose='ERROR') # only keep EEG channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_FeatureExtractor(nn.Module):\n",
    "    # based on \"A deep learning architecture for temporal sleep stage\n",
    "    # classification using multivariate and multimodal time series\"\n",
    "\n",
    "  def __init__(self, C, T, k=50, m=13, dropout_prob=0.5, embedding_dim=100, n_spatial_filters=8):\n",
    "    \"\"\"\n",
    "    C: number of EEG channels\n",
    "    T: number of timepoints in a window\n",
    "    k: length of spatial filters (i.e. how much you look in time)\n",
    "    m: maxpool size\n",
    "    n_spatial_filters: number of spatial filters\n",
    "    embedding_dim: embedding dimension (D)\n",
    "    \"\"\"\n",
    "    # input is (1, C, T) <-- notation (channels, dim1, dim2) is different than paper (dim1, dim2, channels)\n",
    "    super().__init__()\n",
    "    self.depthwise_conv = nn.Conv2d(in_channels=1, out_channels=C, kernel_size=(C,1))\n",
    "    self.spatial_padding = torch.nn.ReflectionPad2d((int(np.floor((k-1)/2)),int(np.ceil((k-1)/2)),0,0))\n",
    "    self.spatialwise_conv1 = nn.Conv2d(in_channels=1, out_channels=n_spatial_filters, kernel_size=(1,k))\n",
    "    self.spatialwise_conv2 = nn.Conv2d(in_channels=n_spatial_filters, out_channels=n_spatial_filters, kernel_size=(1,k))\n",
    "    self.relu = nn.ReLU(inplace=True)\n",
    "    self.maxpool = nn.MaxPool2d(kernel_size=(1,m), stride=(1,m))\n",
    "    self.dropout = nn.Dropout(p=dropout_prob, inplace=True)\n",
    "    self.linear = nn.Linear(n_spatial_filters * C * ((T // m) // m), embedding_dim)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # input is (bs, 1, C, T)\n",
    "    bs = x.shape[0]\n",
    "    out = x\n",
    "    out = self.depthwise_conv(out) # (bs, C, 1, T)\n",
    "    out = out.permute(0,2,1,3) # (bs, 1, C, T)\n",
    "    out = self.spatial_padding(out)\n",
    "    out = self.spatialwise_conv1(out) # (bs, n_spatial_filters, C, T)\n",
    "    out = self.relu(out)\n",
    "    out = self.maxpool(out) # (bs, n_spatial_filters, C, T // m)\n",
    "    out = self.spatial_padding(out)\n",
    "    out = self.spatialwise_conv2(out) # (bs, n_spatial_filters, C, T // m)\n",
    "    out = self.relu(out)\n",
    "    out = self.maxpool(out) # (bs, n_spatial_filters, C, (T // m) // m)\n",
    "    out = out.view(bs, -1) # (bs, n_spatial_filters * C * ((T // m) // m))\n",
    "    out = self.dropout(out)\n",
    "    out = self.linear(out) # (bs, embedding_dim)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedBaseline(nn.Module):\n",
    "    def __init__(self, C, T, n_classes, k=50, m=13, dropout_prob=0.5, n_spatial_filters=8):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = EEG_FeatureExtractor(C, T, k, m, dropout_prob, n_classes, n_spatial_filters)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.feature_extractor(x)\n",
    "        return out\n",
    "\n",
    "    def loss(self, x, y_true):\n",
    "        out = self(x)\n",
    "        return self.loss_fn(out, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "  model.train()\n",
    "  \n",
    "  train_losses = []\n",
    "  for pair in train_loader:\n",
    "    x, y = pair[0], pair[1]\n",
    "    x = x.cuda().float().contiguous()\n",
    "    y = y.cuda().long().contiguous()\n",
    "    loss = model.loss(x, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_losses.append(loss.item())\n",
    "  return train_losses\n",
    "\n",
    "def eval_loss(model, data_loader):\n",
    "  model.eval()\n",
    "  total_loss = 0\n",
    "  with torch.no_grad():\n",
    "    for pair in data_loader:\n",
    "      x, y = pair[0], pair[1]\n",
    "      x = x.cuda().float().contiguous()\n",
    "      y = y.cuda().long().contiguous()\n",
    "      loss = model.loss(x, y)\n",
    "      total_loss += loss * x.shape[0]\n",
    "    avg_loss = total_loss / len(data_loader.dataset)\n",
    "\n",
    "  return avg_loss.item()\n",
    "\n",
    "\n",
    "def train_epochs(model, train_loader, test_loader, train_args):\n",
    "  epochs, lr = train_args['epochs'], train_args['lr']\n",
    "  optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "  train_losses = []\n",
    "  test_losses = [eval_loss(model, test_loader)]\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_losses.extend(train(model, train_loader, optimizer, epoch))\n",
    "    test_loss = eval_loss(model, test_loader)\n",
    "    test_losses.append(test_loss)\n",
    "    print(f'Epoch {epoch}, Test loss {test_loss:.4f}')\n",
    "  return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "  x_normalized = (x - x.mean(2).reshape(x.shape[0],x.shape[1],1))/(x.std(2).reshape(x.shape[0],x.shape[1],1))\n",
    "  return x_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_supervised_baseline(epochs_train, epochs_test):\n",
    "  X_train = normalize(epochs_train.get_data())\n",
    "  y_train = epochs_train.events[:, 2] - 1 # start at 0\n",
    "\n",
    "  X_test = normalize(epochs_test.get_data())\n",
    "  y_test = epochs_test.events[:, 2] - 1\n",
    "  \n",
    "  n_classes = y_train.max() - y_train.min() + 1\n",
    "  C = X_train.shape[1] # num channels\n",
    "  T = X_train.shape[2] # window length\n",
    "  model = SupervisedBaseline(C, T, n_classes).cuda()\n",
    "\n",
    "  train_dataset = data.TensorDataset(torch.tensor(X_train).unsqueeze(1), torch.tensor(y_train))\n",
    "  train_loader = data.DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "  test_dataset = data.TensorDataset(torch.tensor(X_test).unsqueeze(1), torch.tensor(y_test))\n",
    "  test_loader = data.DataLoader(test_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "  train_losses, test_losses = train_epochs(model, train_loader, test_loader, \n",
    "                                         dict(epochs=20, lr=1e-3))\n",
    "\n",
    "  return train_losses, test_losses, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Test loss 0.6182\n",
      "Epoch 1, Test loss 0.5615\n",
      "Epoch 2, Test loss 0.5550\n",
      "Epoch 3, Test loss 0.5539\n",
      "Epoch 4, Test loss 0.5995\n",
      "Epoch 5, Test loss 0.5995\n",
      "Epoch 6, Test loss 0.6319\n",
      "Epoch 7, Test loss 0.6275\n",
      "Epoch 8, Test loss 0.6327\n",
      "Epoch 9, Test loss 0.6494\n",
      "Epoch 10, Test loss 0.6436\n",
      "Epoch 11, Test loss 0.6860\n",
      "Epoch 12, Test loss 0.6726\n",
      "Epoch 13, Test loss 0.7008\n",
      "Epoch 14, Test loss 0.6857\n",
      "Epoch 15, Test loss 0.6962\n",
      "Epoch 16, Test loss 0.6918\n",
      "Epoch 17, Test loss 0.7020\n",
      "Epoch 18, Test loss 0.7588\n",
      "Epoch 19, Test loss 0.8093\n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses, model = train_supervised_baseline(epochs_train, epochs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = normalize(epochs_test.get_data())\n",
    "y_test = epochs_test.events[:, 2] - 1\n",
    "test_dataset = data.TensorDataset(torch.tensor(X_test).unsqueeze(1), torch.tensor(y_test))\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2254c110d0>]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Figure size 432x288 with 1 Axes>\n"
     ]
    }
   ],
   "source": [
    "plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(model, test_loader):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  model.eval()\n",
    "  softmax = nn.Softmax()\n",
    "  with torch.no_grad():\n",
    "    for pair in test_loader:\n",
    "      x, y = pair[0], pair[1]\n",
    "      x = x.cuda().float().contiguous()\n",
    "      y = y.cuda().long().contiguous()\n",
    "      out = model(x)\n",
    "      _, predicted = torch.max(softmax(out.data), 1)\n",
    "      total += y.size(0)\n",
    "      correct += (predicted == y).sum().item()\n",
    "\n",
    "  print(f'Accuracy of the network on the {len(test_loader.dataset)} test images: {round(100 * correct / total)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 27295 test images: 84%\n"
     ]
    }
   ],
   "source": [
    "accuracy_score(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastive Predictive Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudocode:\n",
    "- Get waveform for each recording\n",
    "- Load n=10 waveforms into minibatch\n",
    "- For each waveform, select 3 min patch\n",
    "- encode first\n",
    "- predict 8, each with 8 negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ssl_data(subjects, recordings):\n",
    "    files = fetch_data(subjects=subjects, recording=recordings)\n",
    "    data = []\n",
    "    for x in files:\n",
    "        print(\"Loading\", x[0])\n",
    "        # load the data\n",
    "        edf_file = x[0]\n",
    "        annot_file = x[1]\n",
    "        raw = mne.io.read_raw_edf(edf_file, verbose='ERROR')\n",
    "        annot_train = mne.read_annotations(annot_file)\n",
    "\n",
    "        raw.set_annotations(annot_train, emit_warning=False)\n",
    "        raw.set_channel_types(MAPPING)\n",
    "        \n",
    "        # filter\n",
    "        raw.load_data()\n",
    "        raw.filter(None, 30., fir_design='firwin') # low pass filter\n",
    "        raw.pick_types(eeg=True, verbose='ERROR') # only keep EEG channels\n",
    "\n",
    "        data.append(raw.get_data())\n",
    "    return data\n",
    "# [1,2,3,4,5,,6,7,7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/raphael_hotter/datasets/SC4001E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4011E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4021E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4031E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4041E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4051E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4061E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4071E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4081E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4091E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4101E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4111E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4121E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4131E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4141E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4151E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4161E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4171E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4181E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4191E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4201E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4211E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4221E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4231E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4241E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4251E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4261F0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4271F0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4281G0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4291G0-PSG.edf\n"
     ]
    }
   ],
   "source": [
    "train_data = load_ssl_data(train_subjects, recordings)\n",
    "test_data = load_ssl_data(test_subjects, recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/raphael_hotter/datasets/SC4201E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4211E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4221E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4231E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4241E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4251E0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4261F0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4271F0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4281G0-PSG.edf\n",
      "Loading /home/raphael_hotter/datasets/SC4291G0-PSG.edf\n"
     ]
    }
   ],
   "source": [
    "test_data = load_ssl_data(test_subjects, recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "e = IPython.embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_one(x):\n",
    "  x_normalized = (x - x.mean(1).reshape(x.shape[0],1))/(x.std(1).reshape(x.shape[0],1))\n",
    "  return x_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_delay = 60 # 1 min\n",
    "overlap = 0.5\n",
    "n_context_windows = 8\n",
    "window_length = 30 # s\n",
    "n_predict_windows = 4\n",
    "n_negatives = 4\n",
    "S_FREQ = 100 # samples/sec\n",
    "\n",
    "import random\n",
    "\n",
    "def sample_negative(recording, start_sample, n_samples, n_negatives, window_length=3000):\n",
    "    n_available_positions = recording.shape[1] - n_samples - 2*window_length\n",
    "    random_indices = np.random.choice(n_available_positions, n_negatives)\n",
    "    negative_samples = []\n",
    "    for i in random_indices:\n",
    "      if i < start_sample - window_length:\n",
    "        negative_samples.append(recording[:, i:i+window_length])\n",
    "      else:\n",
    "        idx = i + window_length + n_samples\n",
    "        negative_samples.append(recording[:, idx:idx+window_length])\n",
    "    return negative_samples\n",
    "\n",
    "  # [0,1,2,3,4,5,6,6,7,,8,89,9]\n",
    "\n",
    "def get_minibatch(train_data, bs, n_negatives, n_context_windows, n_predict_windows, overlap, predict_delay):\n",
    "  \"\"\"\n",
    "  Return list has [{\n",
    "    context windows: [[],[],...],\n",
    "    prediction windows: [[],[],...]\n",
    "    negative windows: [[],[],...]\n",
    "  }]\n",
    "  [1,2,3,4,5,5,6,....,8,]\n",
    "  \"\"\"\n",
    "  # sample bs subjects with replacement\n",
    "  context_time = (1 + (n_context_windows-1)*overlap)*window_length\n",
    "  predict_time = (1 + (n_predict_windows-1)*overlap)*window_length\n",
    "  \n",
    "  sample_length = S_FREQ*(context_time + predict_delay + predict_time)\n",
    "  \n",
    "  subjects = random.choices(train_data, k=bs)\n",
    "  minibatch = []\n",
    "  for s in subjects:\n",
    "    s_length = s.shape[1]\n",
    "    start_position = np.random.randint(0, s_length-sample_length)\n",
    "    context_window_start_times = np.arange(start_position,\n",
    "                                           start_position + context_time*S_FREQ - overlap*S_FREQ*window_length,\n",
    "                                           overlap*S_FREQ*window_length)\n",
    "    predict_window_start_times = np.arange(start_position + S_FREQ*context_time + S_FREQ*predict_delay,\n",
    "                                           start_position + S_FREQ*context_time + S_FREQ*predict_delay + S_FREQ*predict_time - overlap*S_FREQ*window_length,\n",
    "                                           overlap*S_FREQ*window_length)\n",
    "    context_windows = [s[:,int(c_time):int(c_time)+S_FREQ*window_length] for c_time in context_window_start_times]\n",
    "    predict_windows = [s[:,int(p_time):int(p_time)+S_FREQ*window_length] for p_time in predict_window_start_times]\n",
    "    negative_windows = [sample_negative(s, int(start_position), int(sample_length), int(n_negatives)) for i in range(len(predict_windows))]\n",
    "\n",
    "    minibatch.append({\n",
    "      \"context_windows\": [normalize_one(c) for c in context_windows],\n",
    "      \"predict_windows\": [normalize_one(c) for c in predict_windows],\n",
    "      \"negative_windows\": [normalize_one(c) for vec in negative_windows for c in vec]\n",
    "    })\n",
    "  \n",
    "  return minibatch\n",
    "  \n",
    "m = get_minibatch(train_data, 100, n_negatives, n_context_windows, n_predict_windows, overlap, predict_delay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2255251610>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(m[0][\"negative_windows\"][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "def train_one_ssl(model, train_data, optimizer, epoch):\n",
    "  model.train()\n",
    "  \n",
    "  train_losses = []\n",
    "  for i in range(10):\n",
    "    minibatch = get_minibatch(train_data, batch_size, n_negatives, n_context_windows, n_predict_windows, overlap, predict_delay)\n",
    "    loss = model.forward(minibatch)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_losses.append(loss.item())\n",
    "  return train_losses\n",
    "\n",
    "def eval_loss_ssl(model, test_data):\n",
    "  model.eval()\n",
    "  total_loss = 0\n",
    "  with torch.no_grad():\n",
    "    for i in range(2):\n",
    "      minibatch = get_minibatch(test_data, batch_size, n_negatives, n_context_windows, n_predict_windows, overlap, predict_delay)\n",
    "      loss = model.forward(minibatch)\n",
    "      total_loss += loss * batch_size\n",
    "    avg_loss = total_loss / (2*batch_size)\n",
    "\n",
    "  return avg_loss.item()\n",
    "\n",
    "def train_epochs_ssl(model, train_data, test_data, train_args):\n",
    "  epochs, lr = train_args['epochs'], train_args['lr']\n",
    "  optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "  train_losses = []\n",
    "  test_losses = [eval_loss_ssl(model, test_data)]\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_losses.extend(train_one_ssl(model, train_data, optimizer, epoch))\n",
    "    test_loss = eval_loss_ssl(model, test_data)\n",
    "    test_losses.append(test_loss)\n",
    "    print(f'Epoch {epoch}, Test loss {test_loss:.4f}')\n",
    "  return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPC_EEG(nn.Module):\n",
    "  def __init__(self, C, T, n_context, n_predict, n_negatives, embedding_dim=100, k=50, m=13, dropout_prob=0.5, n_spatial_filters=8):\n",
    "    super().__init__()\n",
    "    self.n_context = n_context\n",
    "    self.n_predict = n_predict\n",
    "    self.n_negatives = n_negatives\n",
    "    self.C = C\n",
    "    self.T = T\n",
    "    self.feature_extractor = EEG_FeatureExtractor(C, T, k, m, dropout_prob, embedding_dim, n_spatial_filters)\n",
    "    self.cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "  def forward(self, minibatch):\n",
    "    \"\"\"\n",
    "    for each sample:\n",
    "      encode context windows, prediction windows, negative windows\n",
    "      aggregate context windows\n",
    "      compute distances between (1) aggregated context windows and prediction windows encoding\n",
    "                                (2) aggregated context windows and negative windows encoding\n",
    "      do softmax with distances\n",
    "      1 prediction distance and n_neg negative distance\n",
    "      [prediction, neg1 distance, neg2 distance, , , ]\n",
    "      \n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "    for recording_dict in minibatch:\n",
    "      recording_tensor = self.dict_to_tensor(recording_dict)\n",
    "      embeddings = self.feature_extractor(recording_tensor)\n",
    "      aggregated_context = self.aggregate_context_embeddings(embeddings[:self.n_context])\n",
    "      distances = self.compute_distances(aggregated_context, embeddings[self.n_context:])\n",
    "      loss = self.cross_entropy(distances, torch.zeros(len(distances)).cuda().long())\n",
    "      total_loss += loss\n",
    "    return total_loss/len(minibatch)\n",
    "  \n",
    "  def compute_distances(self, aggregated_context, comparison_embeddings):\n",
    "    \"\"\"\n",
    "    Returns (n_predict, n_negatives+1) matrix\n",
    "    \"\"\"\n",
    "    distances_vect = torch.matmul(comparison_embeddings, aggregated_context)\n",
    "    distances = torch.cat((distances_vect[:self.n_predict].unsqueeze(dim=1),\n",
    "                 distances_vect[self.n_predict:].reshape(self.n_predict, self.n_negatives)), dim=1)\n",
    "    return distances\n",
    "  \n",
    "  def aggregate_context_embeddings(self, context_embeddings):\n",
    "    return context_embeddings.mean(dim=0)\n",
    "  \n",
    "  def dict_to_tensor(self, minibatch_dict):\n",
    "    tensor = np.zeros((self.n_context + self.n_predict + self.n_predict*self.n_negatives, 1, self.C, self.T))\n",
    "    tensor[0:self.n_context] = np.array(minibatch_dict[\"context_windows\"]).reshape(-1,1,self.C,self.T)\n",
    "    tensor[self.n_context:self.n_context+self.n_predict] = np.array(minibatch_dict[\"predict_windows\"]).reshape(-1,1,self.C,self.T)\n",
    "    tensor[self.n_context+self.n_predict:] = np.array(minibatch_dict[\"negative_windows\"]).reshape(-1,1,self.C,self.T)\n",
    "    \n",
    "    return torch.from_numpy(tensor).cuda().contiguous().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Test loss 1.5539\n",
      "Epoch 1, Test loss 1.4211\n",
      "Epoch 2, Test loss 1.3722\n",
      "Epoch 3, Test loss 1.3485\n",
      "Epoch 4, Test loss 1.3103\n",
      "Epoch 5, Test loss 1.3221\n",
      "Epoch 6, Test loss 1.2983\n",
      "Epoch 7, Test loss 1.2970\n",
      "Epoch 8, Test loss 1.2950\n",
      "Epoch 9, Test loss 1.2982\n",
      "Epoch 10, Test loss 1.2422\n",
      "Epoch 11, Test loss 1.2890\n",
      "Epoch 12, Test loss 1.3016\n",
      "Epoch 13, Test loss 1.3134\n",
      "Epoch 14, Test loss 1.2675\n",
      "Epoch 15, Test loss 1.2549\n",
      "Epoch 16, Test loss 1.2335\n",
      "Epoch 17, Test loss 1.2287\n",
      "Epoch 18, Test loss 1.1724\n",
      "Epoch 19, Test loss 1.1721\n",
      "Epoch 20, Test loss 1.1556\n",
      "Epoch 21, Test loss 1.1916\n",
      "Epoch 22, Test loss 1.1919\n",
      "Epoch 23, Test loss 1.1951\n",
      "Epoch 24, Test loss 1.1520\n",
      "Epoch 25, Test loss 1.1387\n",
      "Epoch 26, Test loss 1.1862\n",
      "Epoch 27, Test loss 1.1331\n",
      "Epoch 28, Test loss 1.1720\n",
      "Epoch 29, Test loss 1.1684\n",
      "Epoch 30, Test loss 1.0506\n",
      "Epoch 31, Test loss 1.1432\n",
      "Epoch 32, Test loss 1.0980\n",
      "Epoch 33, Test loss 1.1747\n",
      "Epoch 34, Test loss 1.0845\n",
      "Epoch 35, Test loss 1.0600\n",
      "Epoch 36, Test loss 1.0834\n",
      "Epoch 37, Test loss 1.0596\n",
      "Epoch 38, Test loss 1.0407\n",
      "Epoch 39, Test loss 1.0871\n",
      "Epoch 40, Test loss 1.0693\n",
      "Epoch 41, Test loss 1.0852\n",
      "Epoch 42, Test loss 1.1049\n",
      "Epoch 43, Test loss 1.0846\n",
      "Epoch 44, Test loss 1.0528\n",
      "Epoch 45, Test loss 1.0031\n",
      "Epoch 46, Test loss 1.0510\n",
      "Epoch 47, Test loss 1.0921\n",
      "Epoch 48, Test loss 1.0929\n",
      "Epoch 49, Test loss 1.0711\n",
      "Epoch 50, Test loss 1.0489\n",
      "Epoch 51, Test loss 1.0736\n",
      "Epoch 52, Test loss 1.0807\n",
      "Epoch 53, Test loss 1.0467\n",
      "Epoch 54, Test loss 1.0590\n",
      "Epoch 55, Test loss 1.0708\n",
      "Epoch 56, Test loss 0.9786\n",
      "Epoch 57, Test loss 1.0787\n",
      "Epoch 58, Test loss 1.0287\n",
      "Epoch 59, Test loss 1.0653\n",
      "Epoch 60, Test loss 1.0985\n",
      "Epoch 61, Test loss 1.0392\n",
      "Epoch 62, Test loss 1.0225\n",
      "Epoch 63, Test loss 1.0713\n",
      "Epoch 64, Test loss 1.0081\n",
      "Epoch 65, Test loss 1.0337\n",
      "Epoch 66, Test loss 1.0102\n",
      "Epoch 67, Test loss 1.0586\n",
      "Epoch 68, Test loss 1.0072\n",
      "Epoch 69, Test loss 1.0704\n",
      "Epoch 70, Test loss 0.9993\n",
      "Epoch 71, Test loss 1.0603\n",
      "Epoch 72, Test loss 1.0458\n",
      "Epoch 73, Test loss 1.0923\n",
      "Epoch 74, Test loss 1.0904\n",
      "Epoch 75, Test loss 0.9979\n",
      "Epoch 76, Test loss 1.0768\n",
      "Epoch 77, Test loss 1.0871\n",
      "Epoch 78, Test loss 0.9980\n",
      "Epoch 79, Test loss 1.0152\n",
      "Epoch 80, Test loss 1.0910\n",
      "Epoch 81, Test loss 0.9931\n",
      "Epoch 82, Test loss 1.0832\n",
      "Epoch 83, Test loss 1.0514\n",
      "Epoch 84, Test loss 1.0381\n",
      "Epoch 85, Test loss 1.0618\n",
      "Epoch 86, Test loss 1.0497\n",
      "Epoch 87, Test loss 1.0495\n",
      "Epoch 88, Test loss 1.0188\n",
      "Epoch 89, Test loss 1.0356\n",
      "Epoch 90, Test loss 1.0577\n",
      "Epoch 91, Test loss 1.0119\n",
      "Epoch 92, Test loss 1.0098\n",
      "Epoch 93, Test loss 0.9708\n",
      "Epoch 94, Test loss 0.9603\n",
      "Epoch 95, Test loss 0.9951\n",
      "Epoch 96, Test loss 0.9870\n",
      "Epoch 97, Test loss 0.9660\n",
      "Epoch 98, Test loss 1.0690\n",
      "Epoch 99, Test loss 1.0118\n"
     ]
    }
   ],
   "source": [
    "# def train_ssl(train_data, test_data, model):\n",
    "C = 2 # num channels\n",
    "T = 3000 # window length\n",
    "model = CPC_EEG(C, T, n_context_windows, n_predict_windows, n_negatives).cuda()\n",
    "\n",
    "train_losses, test_losses = train_epochs_ssl(model, train_data, test_data,\n",
    "                                       dict(epochs=100, lr=1e-3))\n",
    "\n",
    "#   return train_losses, test_losses, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Test loss 1.0451\n",
      "Epoch 1, Test loss 1.0218\n",
      "Epoch 2, Test loss 1.0043\n",
      "Epoch 3, Test loss 1.0532\n",
      "Epoch 4, Test loss 1.0250\n",
      "Epoch 5, Test loss 1.1007\n",
      "Epoch 6, Test loss 0.9988\n",
      "Epoch 7, Test loss 0.9895\n",
      "Epoch 8, Test loss 1.0892\n",
      "Epoch 9, Test loss 0.9869\n",
      "Epoch 10, Test loss 0.9443\n",
      "Epoch 11, Test loss 1.0045\n",
      "Epoch 12, Test loss 0.9861\n",
      "Epoch 13, Test loss 0.9753\n",
      "Epoch 14, Test loss 1.0174\n",
      "Epoch 15, Test loss 1.0403\n",
      "Epoch 16, Test loss 0.9909\n",
      "Epoch 17, Test loss 0.9772\n",
      "Epoch 18, Test loss 1.0530\n",
      "Epoch 19, Test loss 0.9656\n",
      "Epoch 20, Test loss 1.0752\n",
      "Epoch 21, Test loss 1.0088\n",
      "Epoch 22, Test loss 0.9998\n",
      "Epoch 23, Test loss 0.9563\n",
      "Epoch 24, Test loss 0.9721\n",
      "Epoch 25, Test loss 1.0728\n",
      "Epoch 26, Test loss 0.9239\n",
      "Epoch 27, Test loss 0.9730\n",
      "Epoch 28, Test loss 0.9583\n",
      "Epoch 29, Test loss 1.0023\n",
      "Epoch 30, Test loss 1.0941\n",
      "Epoch 31, Test loss 0.9359\n",
      "Epoch 32, Test loss 0.9431\n",
      "Epoch 33, Test loss 0.9439\n",
      "Epoch 34, Test loss 0.9736\n",
      "Epoch 35, Test loss 1.0053\n",
      "Epoch 36, Test loss 0.9645\n",
      "Epoch 37, Test loss 0.9400\n",
      "Epoch 38, Test loss 0.9236\n",
      "Epoch 39, Test loss 0.9892\n",
      "Epoch 40, Test loss 0.9704\n",
      "Epoch 41, Test loss 1.0455\n",
      "Epoch 42, Test loss 0.9972\n",
      "Epoch 43, Test loss 0.9820\n",
      "Epoch 44, Test loss 0.9981\n",
      "Epoch 45, Test loss 0.9152\n",
      "Epoch 46, Test loss 1.1461\n",
      "Epoch 47, Test loss 0.9918\n",
      "Epoch 48, Test loss 0.9797\n",
      "Epoch 49, Test loss 0.9357\n",
      "Epoch 50, Test loss 0.9727\n",
      "Epoch 51, Test loss 0.9493\n",
      "Epoch 52, Test loss 1.0309\n",
      "Epoch 53, Test loss 1.1034\n",
      "Epoch 54, Test loss 0.9500\n",
      "Epoch 55, Test loss 0.9763\n",
      "Epoch 56, Test loss 1.0007\n",
      "Epoch 57, Test loss 0.9893\n",
      "Epoch 58, Test loss 1.0077\n",
      "Epoch 59, Test loss 0.9322\n",
      "Epoch 60, Test loss 0.9645\n",
      "Epoch 61, Test loss 0.9146\n",
      "Epoch 62, Test loss 0.8738\n",
      "Epoch 63, Test loss 0.9935\n",
      "Epoch 64, Test loss 0.8479\n",
      "Epoch 65, Test loss 1.0380\n",
      "Epoch 66, Test loss 0.8966\n",
      "Epoch 67, Test loss 1.0121\n",
      "Epoch 68, Test loss 0.9397\n",
      "Epoch 69, Test loss 0.9262\n",
      "Epoch 70, Test loss 1.0352\n",
      "Epoch 71, Test loss 0.9392\n",
      "Epoch 72, Test loss 1.0277\n",
      "Epoch 73, Test loss 1.0511\n",
      "Epoch 74, Test loss 1.0266\n",
      "Epoch 75, Test loss 1.0428\n",
      "Epoch 76, Test loss 0.9375\n",
      "Epoch 77, Test loss 0.9311\n",
      "Epoch 78, Test loss 0.9652\n",
      "Epoch 79, Test loss 0.8871\n",
      "Epoch 80, Test loss 0.9451\n",
      "Epoch 81, Test loss 0.9008\n",
      "Epoch 82, Test loss 1.0071\n",
      "Epoch 83, Test loss 0.8625\n",
      "Epoch 84, Test loss 0.9891\n",
      "Epoch 85, Test loss 0.9702\n",
      "Epoch 86, Test loss 0.9569\n",
      "Epoch 87, Test loss 0.9349\n",
      "Epoch 88, Test loss 0.9309\n",
      "Epoch 89, Test loss 0.9297\n",
      "Epoch 90, Test loss 1.0319\n",
      "Epoch 91, Test loss 0.9101\n",
      "Epoch 92, Test loss 0.9514\n",
      "Epoch 93, Test loss 0.9091\n",
      "Epoch 94, Test loss 0.9020\n",
      "Epoch 95, Test loss 0.8906\n",
      "Epoch 96, Test loss 0.9108\n",
      "Epoch 97, Test loss 1.0537\n",
      "Epoch 98, Test loss 0.9340\n",
      "Epoch 99, Test loss 0.9364\n"
     ]
    }
   ],
   "source": [
    "train_losses2, test_losses2 = train_epochs_ssl(model, train_data, test_data,\n",
    "                                       dict(epochs=100, lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Test loss 1.0111\n",
      "Epoch 1, Test loss 0.9454\n",
      "Epoch 2, Test loss 1.0188\n",
      "Epoch 3, Test loss 0.9645\n",
      "Epoch 4, Test loss 0.9688\n",
      "Epoch 5, Test loss 0.9021\n",
      "Epoch 6, Test loss 0.9973\n",
      "Epoch 7, Test loss 0.9498\n",
      "Epoch 8, Test loss 1.0069\n",
      "Epoch 9, Test loss 0.8815\n",
      "Epoch 10, Test loss 0.9796\n",
      "Epoch 11, Test loss 0.8434\n",
      "Epoch 12, Test loss 0.9611\n",
      "Epoch 13, Test loss 0.9654\n",
      "Epoch 14, Test loss 0.8828\n",
      "Epoch 15, Test loss 1.0686\n",
      "Epoch 16, Test loss 0.9316\n",
      "Epoch 17, Test loss 0.9465\n",
      "Epoch 18, Test loss 0.9328\n",
      "Epoch 19, Test loss 0.8993\n",
      "Epoch 20, Test loss 0.9321\n",
      "Epoch 21, Test loss 0.8672\n",
      "Epoch 22, Test loss 0.9673\n",
      "Epoch 23, Test loss 0.9512\n",
      "Epoch 24, Test loss 0.8831\n",
      "Epoch 25, Test loss 0.9372\n",
      "Epoch 26, Test loss 0.9848\n",
      "Epoch 27, Test loss 1.0084\n",
      "Epoch 28, Test loss 0.9549\n",
      "Epoch 29, Test loss 0.9353\n",
      "Epoch 30, Test loss 0.9940\n",
      "Epoch 31, Test loss 0.9281\n",
      "Epoch 32, Test loss 0.9260\n",
      "Epoch 33, Test loss 0.9575\n",
      "Epoch 34, Test loss 0.8774\n",
      "Epoch 35, Test loss 0.8777\n",
      "Epoch 36, Test loss 0.9016\n",
      "Epoch 37, Test loss 1.0205\n",
      "Epoch 38, Test loss 0.9539\n",
      "Epoch 39, Test loss 0.9221\n",
      "Epoch 40, Test loss 0.8845\n",
      "Epoch 41, Test loss 0.9102\n",
      "Epoch 42, Test loss 0.8449\n",
      "Epoch 43, Test loss 1.0369\n",
      "Epoch 44, Test loss 0.9390\n",
      "Epoch 45, Test loss 0.9308\n",
      "Epoch 46, Test loss 1.0436\n",
      "Epoch 47, Test loss 1.0402\n",
      "Epoch 48, Test loss 0.9774\n",
      "Epoch 49, Test loss 0.9332\n",
      "Epoch 50, Test loss 1.0007\n",
      "Epoch 51, Test loss 0.9267\n",
      "Epoch 52, Test loss 1.0169\n",
      "Epoch 53, Test loss 0.9479\n",
      "Epoch 54, Test loss 0.9064\n",
      "Epoch 55, Test loss 0.9165\n",
      "Epoch 56, Test loss 0.9090\n",
      "Epoch 57, Test loss 0.9651\n",
      "Epoch 58, Test loss 0.9491\n",
      "Epoch 59, Test loss 0.9266\n",
      "Epoch 60, Test loss 1.0242\n",
      "Epoch 61, Test loss 0.9023\n",
      "Epoch 62, Test loss 0.9786\n",
      "Epoch 63, Test loss 0.8814\n",
      "Epoch 64, Test loss 0.9464\n",
      "Epoch 65, Test loss 0.8948\n",
      "Epoch 66, Test loss 1.0071\n",
      "Epoch 67, Test loss 0.8555\n",
      "Epoch 68, Test loss 0.8622\n",
      "Epoch 69, Test loss 0.9570\n",
      "Epoch 70, Test loss 0.9677\n",
      "Epoch 71, Test loss 0.8966\n",
      "Epoch 72, Test loss 0.9923\n",
      "Epoch 73, Test loss 0.9127\n",
      "Epoch 74, Test loss 1.0027\n",
      "Epoch 75, Test loss 0.9926\n",
      "Epoch 76, Test loss 0.9041\n",
      "Epoch 77, Test loss 0.9511\n",
      "Epoch 78, Test loss 1.0365\n",
      "Epoch 79, Test loss 0.9629\n",
      "Epoch 80, Test loss 0.9494\n",
      "Epoch 81, Test loss 0.8350\n",
      "Epoch 82, Test loss 1.0221\n",
      "Epoch 83, Test loss 0.8850\n",
      "Epoch 84, Test loss 0.9886\n",
      "Epoch 85, Test loss 1.0088\n",
      "Epoch 86, Test loss 0.9288\n",
      "Epoch 87, Test loss 1.0344\n",
      "Epoch 88, Test loss 0.9425\n",
      "Epoch 89, Test loss 0.9159\n",
      "Epoch 90, Test loss 0.9766\n",
      "Epoch 91, Test loss 0.9859\n",
      "Epoch 92, Test loss 0.8793\n",
      "Epoch 93, Test loss 0.9613\n",
      "Epoch 94, Test loss 0.8807\n",
      "Epoch 95, Test loss 0.8977\n",
      "Epoch 96, Test loss 0.9761\n",
      "Epoch 97, Test loss 0.9557\n",
      "Epoch 98, Test loss 0.9263\n",
      "Epoch 99, Test loss 0.9283\n"
     ]
    }
   ],
   "source": [
    "train_losses3, test_losses3 = train_epochs_ssl(model, train_data, test_data,\n",
    "                                       dict(epochs=100, lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Test loss 0.9229\n",
      "Epoch 1, Test loss 0.8735\n",
      "Epoch 2, Test loss 1.0025\n",
      "Epoch 3, Test loss 0.8785\n",
      "Epoch 4, Test loss 1.0112\n",
      "Epoch 5, Test loss 0.8711\n",
      "Epoch 6, Test loss 0.9217\n",
      "Epoch 7, Test loss 0.8711\n",
      "Epoch 8, Test loss 0.9799\n",
      "Epoch 9, Test loss 0.8482\n",
      "Epoch 10, Test loss 0.8959\n",
      "Epoch 11, Test loss 0.9526\n",
      "Epoch 12, Test loss 0.9962\n",
      "Epoch 13, Test loss 0.9109\n",
      "Epoch 14, Test loss 0.9240\n",
      "Epoch 15, Test loss 0.9302\n",
      "Epoch 16, Test loss 0.9124\n",
      "Epoch 17, Test loss 0.9606\n",
      "Epoch 18, Test loss 1.0549\n",
      "Epoch 19, Test loss 0.8558\n",
      "Epoch 20, Test loss 0.9101\n",
      "Epoch 21, Test loss 0.9254\n",
      "Epoch 22, Test loss 0.9073\n",
      "Epoch 23, Test loss 0.8735\n",
      "Epoch 24, Test loss 0.9180\n",
      "Epoch 25, Test loss 0.8990\n",
      "Epoch 26, Test loss 0.9236\n",
      "Epoch 27, Test loss 0.9412\n",
      "Epoch 28, Test loss 0.9270\n",
      "Epoch 29, Test loss 0.9190\n",
      "Epoch 30, Test loss 0.8865\n",
      "Epoch 31, Test loss 0.9242\n",
      "Epoch 32, Test loss 0.8395\n",
      "Epoch 33, Test loss 0.8733\n",
      "Epoch 34, Test loss 0.9152\n",
      "Epoch 35, Test loss 1.0448\n",
      "Epoch 36, Test loss 0.9222\n",
      "Epoch 37, Test loss 1.0280\n",
      "Epoch 38, Test loss 0.8331\n",
      "Epoch 39, Test loss 0.9123\n",
      "Epoch 40, Test loss 0.9669\n",
      "Epoch 41, Test loss 0.9652\n",
      "Epoch 42, Test loss 0.8560\n",
      "Epoch 43, Test loss 0.9401\n",
      "Epoch 44, Test loss 0.9518\n",
      "Epoch 45, Test loss 0.9063\n",
      "Epoch 46, Test loss 0.8833\n",
      "Epoch 47, Test loss 0.9565\n",
      "Epoch 48, Test loss 1.0279\n",
      "Epoch 49, Test loss 0.8451\n",
      "Epoch 50, Test loss 0.8528\n",
      "Epoch 51, Test loss 0.8816\n",
      "Epoch 52, Test loss 0.8846\n",
      "Epoch 53, Test loss 1.0669\n",
      "Epoch 54, Test loss 0.9490\n",
      "Epoch 55, Test loss 1.0072\n",
      "Epoch 56, Test loss 0.9625\n",
      "Epoch 57, Test loss 0.9984\n",
      "Epoch 58, Test loss 1.0252\n",
      "Epoch 59, Test loss 0.9202\n",
      "Epoch 60, Test loss 0.8306\n",
      "Epoch 61, Test loss 0.8487\n",
      "Epoch 62, Test loss 1.0120\n",
      "Epoch 63, Test loss 0.9548\n",
      "Epoch 64, Test loss 0.8897\n",
      "Epoch 65, Test loss 0.8208\n",
      "Epoch 66, Test loss 0.9219\n",
      "Epoch 67, Test loss 0.8417\n",
      "Epoch 68, Test loss 0.9481\n",
      "Epoch 69, Test loss 0.8957\n",
      "Epoch 70, Test loss 0.8403\n",
      "Epoch 71, Test loss 0.9543\n",
      "Epoch 72, Test loss 0.9278\n",
      "Epoch 73, Test loss 0.9194\n",
      "Epoch 74, Test loss 0.8723\n",
      "Epoch 75, Test loss 0.8801\n",
      "Epoch 76, Test loss 0.8319\n",
      "Epoch 77, Test loss 0.9140\n",
      "Epoch 78, Test loss 0.9429\n",
      "Epoch 79, Test loss 0.8782\n",
      "Epoch 80, Test loss 0.8830\n",
      "Epoch 81, Test loss 0.9542\n",
      "Epoch 82, Test loss 0.9224\n",
      "Epoch 83, Test loss 0.9006\n",
      "Epoch 84, Test loss 0.9044\n",
      "Epoch 85, Test loss 0.9302\n",
      "Epoch 86, Test loss 0.9060\n",
      "Epoch 87, Test loss 0.9158\n",
      "Epoch 88, Test loss 0.9388\n",
      "Epoch 89, Test loss 0.9562\n",
      "Epoch 90, Test loss 0.9121\n",
      "Epoch 91, Test loss 0.9337\n",
      "Epoch 92, Test loss 0.9119\n",
      "Epoch 93, Test loss 0.9077\n",
      "Epoch 94, Test loss 0.8349\n",
      "Epoch 95, Test loss 0.8873\n",
      "Epoch 96, Test loss 0.8713\n",
      "Epoch 97, Test loss 0.8879\n",
      "Epoch 98, Test loss 0.9471\n",
      "Epoch 99, Test loss 0.9080\n"
     ]
    }
   ],
   "source": [
    "train_losses4, test_losses4 = train_epochs_ssl(model, train_data, test_data,\n",
    "                                       dict(epochs=100, lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Test loss 0.8770\n",
      "Epoch 1, Test loss 0.8133\n",
      "Epoch 2, Test loss 0.9001\n",
      "Epoch 3, Test loss 0.8899\n",
      "Epoch 4, Test loss 0.8898\n",
      "Epoch 5, Test loss 0.8984\n",
      "Epoch 6, Test loss 0.9111\n",
      "Epoch 7, Test loss 0.8456\n",
      "Epoch 8, Test loss 0.9540\n",
      "Epoch 9, Test loss 0.9364\n",
      "Epoch 10, Test loss 0.8976\n",
      "Epoch 11, Test loss 0.9443\n",
      "Epoch 12, Test loss 0.9019\n",
      "Epoch 13, Test loss 0.9336\n",
      "Epoch 14, Test loss 0.9007\n",
      "Epoch 15, Test loss 0.9223\n",
      "Epoch 16, Test loss 0.8445\n",
      "Epoch 17, Test loss 0.8830\n",
      "Epoch 18, Test loss 0.8982\n",
      "Epoch 19, Test loss 0.8027\n",
      "Epoch 20, Test loss 0.8919\n",
      "Epoch 21, Test loss 0.9132\n",
      "Epoch 22, Test loss 0.8371\n",
      "Epoch 23, Test loss 0.8919\n",
      "Epoch 24, Test loss 0.9551\n",
      "Epoch 25, Test loss 0.8611\n",
      "Epoch 26, Test loss 0.9340\n",
      "Epoch 27, Test loss 0.9119\n",
      "Epoch 28, Test loss 0.9297\n",
      "Epoch 29, Test loss 0.9084\n",
      "Epoch 30, Test loss 0.8957\n",
      "Epoch 31, Test loss 0.9222\n",
      "Epoch 32, Test loss 0.8697\n",
      "Epoch 33, Test loss 0.8626\n",
      "Epoch 34, Test loss 0.9264\n",
      "Epoch 35, Test loss 0.9006\n",
      "Epoch 36, Test loss 0.9656\n",
      "Epoch 37, Test loss 0.8668\n",
      "Epoch 38, Test loss 0.8095\n",
      "Epoch 39, Test loss 0.9132\n",
      "Epoch 40, Test loss 0.8487\n",
      "Epoch 41, Test loss 0.8604\n",
      "Epoch 42, Test loss 0.9476\n",
      "Epoch 43, Test loss 0.9327\n",
      "Epoch 44, Test loss 0.9229\n",
      "Epoch 45, Test loss 0.8829\n",
      "Epoch 46, Test loss 0.8420\n",
      "Epoch 47, Test loss 0.8804\n",
      "Epoch 48, Test loss 0.9160\n",
      "Epoch 49, Test loss 0.8951\n",
      "Epoch 50, Test loss 0.9700\n",
      "Epoch 51, Test loss 0.8911\n",
      "Epoch 52, Test loss 0.8994\n",
      "Epoch 53, Test loss 0.9323\n",
      "Epoch 54, Test loss 0.8447\n",
      "Epoch 55, Test loss 0.8609\n",
      "Epoch 56, Test loss 0.9156\n",
      "Epoch 57, Test loss 0.8504\n",
      "Epoch 58, Test loss 0.9285\n",
      "Epoch 59, Test loss 0.9001\n",
      "Epoch 60, Test loss 0.8794\n",
      "Epoch 61, Test loss 0.9230\n",
      "Epoch 62, Test loss 0.9104\n",
      "Epoch 63, Test loss 0.9758\n",
      "Epoch 64, Test loss 0.8860\n",
      "Epoch 65, Test loss 0.7760\n",
      "Epoch 66, Test loss 0.8708\n",
      "Epoch 67, Test loss 0.8136\n",
      "Epoch 68, Test loss 0.8197\n",
      "Epoch 69, Test loss 0.9307\n",
      "Epoch 70, Test loss 0.8751\n",
      "Epoch 71, Test loss 0.9407\n",
      "Epoch 72, Test loss 0.9192\n",
      "Epoch 73, Test loss 0.8297\n",
      "Epoch 74, Test loss 0.9176\n",
      "Epoch 75, Test loss 0.9744\n",
      "Epoch 76, Test loss 0.9391\n",
      "Epoch 77, Test loss 0.8381\n",
      "Epoch 78, Test loss 0.8958\n",
      "Epoch 79, Test loss 0.8116\n",
      "Epoch 80, Test loss 0.8913\n",
      "Epoch 81, Test loss 0.9577\n",
      "Epoch 82, Test loss 0.8750\n",
      "Epoch 83, Test loss 0.9198\n",
      "Epoch 84, Test loss 0.8692\n",
      "Epoch 85, Test loss 0.9163\n",
      "Epoch 86, Test loss 0.8757\n",
      "Epoch 87, Test loss 0.9014\n",
      "Epoch 88, Test loss 0.8953\n",
      "Epoch 89, Test loss 0.8355\n",
      "Epoch 90, Test loss 0.8565\n",
      "Epoch 91, Test loss 0.8318\n",
      "Epoch 92, Test loss 0.8673\n",
      "Epoch 93, Test loss 0.9529\n",
      "Epoch 94, Test loss 0.8631\n",
      "Epoch 95, Test loss 0.9355\n",
      "Epoch 96, Test loss 0.8284\n",
      "Epoch 97, Test loss 0.8520\n",
      "Epoch 98, Test loss 0.9224\n",
      "Epoch 99, Test loss 0.8232\n"
     ]
    }
   ],
   "source": [
    "train_losses5, test_losses5 = train_epochs_ssl(model, train_data, test_data,\n",
    "                                       dict(epochs=100, lr=5e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSL_Linear(nn.Module):\n",
    "  def __init__(self, model):\n",
    "    super().__init__()\n",
    "    self.model = model\n",
    "    self.model.requires_grad = False\n",
    "    self.linear = nn.Linear(100, 5)\n",
    "    self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "  def forward(self, x):\n",
    "    with torch.no_grad():\n",
    "      features = self.model.feature_extractor(x)\n",
    "    out = self.linear(features)\n",
    "    return out\n",
    "\n",
    "  def loss(self, x, y_true):\n",
    "    out = self(x)\n",
    "    return self.loss_fn(out, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_ssl(epochs_train, epochs_test):\n",
    "  X_train = normalize(epochs_train.get_data())\n",
    "  y_train = epochs_train.events[:, 2] - 1 # start at 0\n",
    "\n",
    "  X_test = normalize(epochs_test.get_data())\n",
    "  y_test = epochs_test.events[:, 2] - 1\n",
    "  \n",
    "  linear_model = SSL_Linear(model).cuda()\n",
    "\n",
    "  train_dataset = data.TensorDataset(torch.tensor(X_train).unsqueeze(1), torch.tensor(y_train))\n",
    "  train_loader = data.DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "  test_dataset = data.TensorDataset(torch.tensor(X_test).unsqueeze(1), torch.tensor(y_test))\n",
    "  test_loader = data.DataLoader(test_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "  train_losses, test_losses = train_epochs(linear_model, train_loader, test_loader, \n",
    "                                         dict(epochs=5, lr=1e-3))\n",
    "\n",
    "  return train_losses, test_losses, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Test loss 0.5934\n",
      "Epoch 1, Test loss 0.4655\n",
      "Epoch 2, Test loss 0.4147\n",
      "Epoch 3, Test loss 0.3893\n",
      "Epoch 4, Test loss 0.3760\n"
     ]
    }
   ],
   "source": [
    "train_losses_linear, test_losses_linear, linear_model = train_linear_ssl(epochs_train, epochs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = normalize(epochs_test.get_data())\n",
    "y_test = epochs_test.events[:, 2] - 1\n",
    "\n",
    "test_dataset = data.TensorDataset(torch.tensor(X_test).unsqueeze(1), torch.tensor(y_test))\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "e = IPython.embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(linear_model, test_loader):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  linear_model.eval()\n",
    "  softmax = nn.Softmax()\n",
    "  with torch.no_grad():\n",
    "    for pair in test_loader:\n",
    "      x, y = pair[0], pair[1]\n",
    "      x = x.cuda().float().contiguous()\n",
    "      y = y.cuda().long().contiguous()\n",
    "      out = linear_model(x)\n",
    "      _, predicted = torch.max(softmax(out.data), 1)\n",
    "      total += y.size(0)\n",
    "      correct += (predicted == y).sum().item()\n",
    "\n",
    "  print(f'Accuracy of the network on the {len(test_loader.dataset)} test images: {round(100 * correct / total)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 27295 test images: 86%\n"
     ]
    }
   ],
   "source": [
    "accuracy_score(linear_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train.plot(duration=60, scalings='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train.plot_psd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = raw_train.pick_types(eeg=True)\n",
    "a = A[:][0]"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
